---
title: "Predicting Customer Credit Risk with Decision Trees and Random Forests"
author: "Stefany Ayala"
output: html_document
---

## Objective
Explore and clean the German Credit dataset, perform exploratory data analysis (EDA), and build classification models (Decision Tree and Random Forest) to predict creditworthiness (Good vs. Bad).

## Libraries
```{r setup, message=FALSE, warning=FALSE}
# Load necessary libraries
library(readxl)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(randomForest)
library(dplyr)
library(knitr)
library(kableExtra)
library(gridExtra)

# Set global options for the document
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

### Data Loading
```{r data-loading}
# Define data source and local file
url <- "https://drive.google.com/uc?id=1vG_m6jCz-nwYwowTbMxwtVrmGtSTUhcH&export=download"
local_file <- "German_Credit.xls"

# Download and load data
if (!file.exists(local_file)) {
  # Download the dataset if it does not already exist locally
  download.file(url, destfile = local_file, mode = "wb")
}

# Read the dataset into an R data frame
German_Credit <- read_excel(local_file)

# Inspect the structure of the dataset
str(German_Credit)
kable(summary(German_Credit), format = "html") %>%
  kable_styling() %>%
  scroll_box(width = "100%")
```

### Functions
```{r functions}
# Function for data cleaning
clean_data <- function(data) {
  data <- data %>%
    rename_all(~ gsub("[^a-zA-Z0-9_]+", "_", .)) %>% # Sanitize column names
    mutate(across(c("CHK_ACCT", "HISTORY", "SAV_ACCT", "EMPLOYMENT", "PRESENT_RESIDENT", "JOB", "RESPONSE"), as.factor))
  return(data)
}

# Function for EDA
eda <- function(data) {
  # Print summary statistics
  print(summary(data))
  response_proportion <- prop.table(table(data$RESPONSE))
  kable(as.data.frame(response_proportion), col.names = c("Response", "Proportion"), format = "html") %>%
    kable_styling(full_width = FALSE)

  # Calculate summary stats for numeric variables
  numeric_vars <- c("DURATION", "AMOUNT", "AGE", "INSTALL_RATE", "NUM_DEPENDENTS")
  summary_stats <- data %>%
    summarise(across(all_of(numeric_vars), list(mean = ~mean(.x, na.rm = TRUE), sd = ~sd(.x, na.rm = TRUE))))
  kable(summary_stats, format = "html") %>% kable_styling(full_width = TRUE)

  # Generate boxplots for key relationships
  p1 <- ggplot(data, aes(x = factor(RESPONSE), y = DURATION)) +
    geom_boxplot() +
    labs(x = "Response", y = "Duration", title = "Duration by Response")
  p2 <- ggplot(data, aes(x = factor(RESPONSE), y = AMOUNT)) +
    geom_boxplot() +
    labs(x = "Response", y = "Amount", title = "Amount by Response")

  # Arrange the boxplots side by side
  gridExtra::grid.arrange(p1, p2, ncol = 2)
}

# Function for model training and evaluation
train_evaluate_models <- function(train_data, test_data) {
  # Decision Tree Model
  decision_tree <- rpart(RESPONSE ~ ., data = train_data, method = "class", parms = list(split = "gini"),
                         control = rpart.control(xval = 5, cp = 0.01))
  rpart.plot(decision_tree, main = "Decision Tree")

  # Random Forest Model
  random_forest <- randomForest(RESPONSE ~ ., data = train_data, ntree = 200, mtry = 5, importance = TRUE)

  # Display variable importance for the Random Forest model
  randomForest::varImpPlot(random_forest, cex = 0.5, main = "Random Forest Variable Importance")

  # Model Evaluation
  decision_tree_predictions <- predict(decision_tree, test_data, type = "class")
  random_forest_predictions <- predict(random_forest, test_data, type = "class")

  decision_tree_accuracy <- mean(decision_tree_predictions == test_data$RESPONSE)
  random_forest_accuracy <- mean(random_forest_predictions == test_data$RESPONSE)

  # Print accuracy metrics
  cat("Decision Tree Accuracy:", decision_tree_accuracy, "\n")
  cat("Random Forest Accuracy:", random_forest_accuracy, "\n")
}
```

### Data Cleaning
```{r data-cleaning}
# Clean the dataset using the custom function
German_Credit <- clean_data(German_Credit)

# Check for missing values
missing_vals <- sum(is.na(German_Credit))
cat("Number of missing values:", missing_vals, "\n")
```

### Exploratory Data Analysis (EDA)
```{r eda}
# Perform EDA using the custom function
eda(German_Credit)
```

### Modeling
```{r modeling}
# Split the data into training and testing sets
set.seed(1234)  # Set seed for reproducibility
index <- sample(2, nrow(German_Credit), replace = TRUE, prob = c(0.7, 0.3))
train_data <- German_Credit[index == 1, ]
test_data <- German_Credit[index == 2, ]

# Train and evaluate models using the custom function
train_evaluate_models(train_data, test_data)
```

### Conclusion
```{r conclusion, echo=FALSE}
cat("- The Random Forest model showed higher predictive power compared to the Decision Tree.\n")
cat("- Key predictive features include Checking Account and Credit Amount.\n")
cat("- Future improvements could involve hyperparameter tuning and expanding feature engineering.")
```
